<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>ETC1010 - 5510: Introduction to Data Analysis</title>
    <meta charset="utf-8" />
    <meta name="author" content="Patricia Menéndez" />
    <script src="libs/header-attrs-2.10/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/ninjutsu.css" rel="stylesheet" />
    <!--
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js"></script> 
    -->
    <link rel="icon" href="images/favicon.ico"  type='image/x-icon'/>    
    <link rel="stylesheet" href="assets/animate.css" type="text/css" />
    <link rel="stylesheet" href="assets/monash-logo.css" type="text/css" />
    <link rel="stylesheet" href="assets/monash-brand.css" type="text/css" />
    <link rel="stylesheet" href="assets/monash-fonts.css" type="text/css" />
    <link rel="stylesheet" href="assets/styles.css" type="text/css" />
    <link rel="stylesheet" href="assets/custom.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">




background-image: url(images/daniel-olah-pCcGpVsOHoo-unsplash.jpg)
background-size: cover
class: hide-slide-number split-70 title-slide
count: false

.column.shade_black[.content[

&lt;br&gt;

# .monash-white.outline-text[ETC1010 - 5510: Introduction to Data Analysis]

&lt;h2 class="monash-white outline-text" style="font-size: 30pt!important;"&gt;Week 11&lt;/h2&gt;

&lt;br&gt;

&lt;h2 style="font-weight:900!important;"&gt;Classification Trees&lt;/h2&gt;

.bottom_abs.width100[

Lecturer: *Patricia Menéndez*

Department of Econometrics and Business Statistics




&lt;br&gt;
]


]]



&lt;div class="column transition monash-m-new delay-1s" style="clip-path:url(#swipe__clip-path);"&gt;
&lt;div class="background-image" style="background-image:url('images/large.png');background-position: center;background-size:cover;"&gt;
&lt;svg class="clip-svg absolute"&gt;
&lt;defs&gt;
&lt;clipPath id="swipe__clip-path" clipPathUnits="objectBoundingBox"&gt;
&lt;polygon points="0.5745 0, 0.5 0.33, 0.42 0, 0 0, 0 1, 0.27 1, 0.27 0.59, 0.37 1, 0.634 1, 0.736 0.59, 0.736 1, 1 1, 1 0, 0.5745 0" /&gt;
&lt;/clipPath&gt;
&lt;/defs&gt;	
&lt;/svg&gt;
&lt;/div&gt;
&lt;/div&gt;








  
  

  
  
---
# Questions/Comments/Suggestions

&lt;img src="images/rhythm-goyal-_-Ofoh09q_o-unsplash.jpg" width="80%" style="display: block; margin: auto;" /&gt;
 Photo: Rhythm Goyal for  Unsplash.


---
# Recap: Week 10

&lt;br&gt;&lt;br&gt;

- A bit more on Networks 
- Decision trees
- How is it computed?
- Decision trees goodness of fit
- Comparison with linear models



---

# Week 11: Outline
&lt;br&gt;&lt;br&gt;

- Assignment 2 peer review feedback form
- Classification trees
- Presentations Week 12 (during tutorial hours)
- Data Analysis Exercise Week 12 (during lecture time)


---
# Assignment 2 peer review form
&lt;br&gt;
- You will have the opportunity to provide feedback on any team member that did not contribute equally to the assignment.
- That includes not completed the individual assignment
- not participating in meetings
- not collaborating equally as the other team members

&lt;br&gt;
**You only need to provide feedback for team members that do not collaborated actively**


---
# Peer review feedback

&lt;img src="images/pr.png" width="70%" style="display: block; margin: auto;" /&gt;

---
class: transition

# Decision Trees
&lt;br&gt;
- Regression trees
- Classification trees



---
# Tree-based methods
&lt;br&gt;&lt;br&gt;
.content-box-neutral[
.green[Regression trees]: Are computational methods that allow us 
to understand the relationship between different 
explanatory variables (x's) with a response variable.
]
.content-box-neutral[
.green[Classification tree]s: Are computation methods that allow us
to find groups in a data set
]







---

# Regression Trees

- Regression trees give the predicted response for an observation by using the mean response of the observations that belong to the
same terminal node (partition)

&lt;img src="Workshop1-Week11_files/figure-html/show-reg-pred0-1.png" width="100%" style="display: block; margin: auto;" /&gt;


---
# Regression Tree

.pull-left[
&lt;img src="Workshop1-Week11_files/figure-html/reg-tree-split-1.png" width="100%" style="display: block; margin: auto;" /&gt;
]

.pull-right[
&lt;img src="Workshop1-Week11_files/figure-html/show-split-1.png" width="100%" style="display: block; margin: auto;" /&gt;

]


---
# Regression Tree

.pull-left[
&lt;img src="Workshop1-Week11_files/figure-html/show-split-again-1.png" width="100%" style="display: block; margin: auto;" /&gt;
]

.pull-right[
&lt;img src="Workshop1-Week11_files/figure-html/rpart-plot-1.png" width="100%" style="display: block; margin: auto;" /&gt;
]

---
# How about if the response variable Y is categorical?

- Then our interest is in  predicting something being in a particular group.
- Say, predicting whether someone passes a course based on two exam scores.
- **Moving from continuous to categorical response**.

&lt;img src="Workshop1-Week11_files/figure-html/unnamed-chunk-3-1.png" width="80%" style="display: block; margin: auto;" /&gt;


---
# What is a decision tree?
&lt;br&gt;
.pull-left[
Tree based models consist of one or more of nested
`if-then` statements for the predictors that partition
the data. Within these partitions, a model is used to predict the outcome.
]

&lt;br&gt;
.pull-right[

```r
include_graphics("images/tree.jpg")
```

&lt;img src="images/tree.jpg" width="100%" style="display: block; margin: auto;" /&gt;

.small[Source: [Egor Dezhic](becominghuman.ai)]

]


---
# Regression? Classification?
  
- Regression trees (quantitative response) give the predicted response for an observation by using the mean response of the observations that belong to the
same terminal node:

&lt;img src="Workshop1-Week11_files/figure-html/show-reg-pred-1.png" width="100%" style="display: block; margin: auto;" /&gt;


---
# Classification
&lt;br&gt;&lt;br&gt;

A .green[classification tree] predicts each observation belonging to the most commonly occurring class/group of observations.

However, when we interpret a classification tree, we are often interested not only in the class prediction (what is most common), but also the proportion of correct classifications.

---
# Building a classification tree
&lt;br&gt;&lt;br&gt;
- Similar approach to building a classification tree as for regression trees
- We use this "recursive binary splitting" approach
- But we don't use the residual sums of squares


$$
SS_T = \sum (y_i-\bar{y})^2
$$


Since we now have a category, we need some way to describe that.

We need something else!

---
# Classification tree
&lt;br&gt;&lt;br&gt;
- We can use the .green["classification error"]:
.content-box-neutral[
 Where we count up the number of miss-classified things, and choose the split that has the lowest number of miss-classified things.]
We can represent this in an equation as the .green[fraction of observations in a region which don't belong to the most common class].

 
`$$E = 1 - \text{max}_{k}(\hat{p}_{mk})$$`

Here,  `\(\hat{p}_{mk}\)` refers to the proportion of observations in the `\(m\)`th region, from the `\(k\)`th class. 

---
# Understanding classification
&lt;br&gt;&lt;br&gt;
What happens when E is zero, and when E is 1?

&lt;br&gt;
`\(E = 1 - \text{max}_{k}(\hat{p}_{mk})\)`

&lt;br&gt;

- E is zero when `\(\text{max}_{k}(\hat{p}_{mk})\)` is 1 --&gt;  which is 1 when observations are the same class
- E = 1 --&gt; nothing was classified correctly!


---
# Classification trees
&lt;br&gt;&lt;br&gt;

- A classification tree is used to predict a .orange[**categorical response**] and regression tree is used to predict a quantitative response
- .green[Use a recursive binary splitting to grow a classification tree. That is, sequentially break the data into two subsets, typically using a single variable each time].
- The predicted value for a new observation, `\(x_0\)`, will be the .green[most commonly occurring class] of observations in the sub-region in which `\(x_0\)` falls


---
# Predicting pass or fail ?

Consider the dataset `Exam` where two exam scores are given for each student, 
and a class `Label` represents whether they passed or failed the course.

.pull-left[

```r
head(data,4)
##      Exam1    Exam2 Label
## 1 34.62366 78.02469     0
## 2 30.28671 43.89500     0
## 3 35.84741 72.90220     0
## 4 60.18260 86.30855     1
```
]

.pull-right[
&lt;img src="Workshop1-Week11_files/figure-html/unnamed-chunk-4-1.png" width="100%" style="display: block; margin: auto;" /&gt;
]


---
# Calculate the number of misclassifications

Along all splits for `Exam1` classifying according to the majority class for the left and right splits
 
&lt;img src="gifs/two_d_cart.gif" width="60%" style="display: block; margin: auto;" /&gt;

Red dots are .orange["fails"], blue dots are .green["passes"], and crosses indicate misclassifications. .small[Source: John Ormerod, U.Syd]

---
# Calculate the number of misclassifications

Along all splits for `Exam2` classifying according to the majority class for the top and bottom splits

&lt;img src="gifs/two_d_cart2.gif" width="60%" style="display: block; margin: auto;" /&gt;

Red dots are .orange["fails"], blue dots are .green["passes"], and crosses indicate misclassifications. .small[Source: John Ormerod, U.Syd]

---
# Combining the results from `Exam1` and `Exam2` splits
&lt;br&gt;&lt;br&gt;
- The minimum number of misclassifications from using all possible splits of `Exam1` was 19 when the value of `Exam1` was **56.7**
- The minimum number of misclassifications from using all possible splits of `Exam2` was 23 when the value of `Exam2` was .orange[52.5]

So we split on the best of these, i.e., split the data on `Exam1` at 56.7.

---
# Split criteria - purity/impurity metrics
&lt;br&gt;
.green[It turns out that classification error is not sufficiently sensitive for tree-growing].
&lt;br&gt;
In practice two other measures are preferable, as they are more sensitive:
&lt;br&gt;
.content-box-soft[
- The Gini Index (Gini impurity) --&gt; probability of misclassifying an observation. The lower the Gini the better the split.
- Information Entropy --&gt; measure of disorder/homogeneity of the sample --&gt; low level of purity
]
They are both quite similar numerically. 

- .green[Small values] mean that a node contains mostly observations of a single class, referred to as .green[node purity].

---
# Example - predicting heart disease

`\(Y\)`: presence of heart disease (Yes/No)

`\(X\)`: heart and lung function measurements


```
##  [1] "Age"       "Sex"       "ChestPain" "RestBP"    "Chol"      "Fbs"      
##  [7] "RestECG"   "MaxHR"     "ExAng"     "Oldpeak"   "Slope"     "Ca"       
## [13] "Thal"      "AHD"
```


&lt;img src="Workshop1-Week11_files/figure-html/rpart-heart-1.png" width="70%" style="display: block; margin: auto;" /&gt;

---
# Deeper trees

Trees can be built deeper by:

- decreasing the value of the complexity parameter `cp`, which sets the difference between impurity values required to continue splitting.
- reducing  the `minsplit` and `minbucket` parameters,  which control the number of  observations  below splits are forbidden.

&lt;img src="Workshop1-Week11_files/figure-html/deeper-trees-1.png" width="70%" style="display: block; margin: auto;" /&gt;

---
# Tabulate true vs predicted to make a .orange[confusion table]. 

&lt;center&gt;
&lt;table&gt;
&lt;tr&gt;  &lt;td&gt; &lt;/td&gt;&lt;td&gt; &lt;/td&gt; &lt;td colspan="2" align="center" &gt; true &lt;/td&gt; &lt;/tr&gt;
&lt;tr&gt;  &lt;td&gt; &lt;/td&gt;&lt;td&gt; &lt;/td&gt; &lt;td align="center" bgcolor="#daf2e9" width="80px"&gt; C1 (positive) &lt;/td&gt; &lt;td align="center" bgcolor="#daf2e9" width="80px"&gt; C2 (negative) &lt;/td&gt; &lt;/tr&gt;
&lt;tr height="50px"&gt;  &lt;td&gt; pred- &lt;/td&gt;&lt;td bgcolor="#daf2e9"&gt; C1 &lt;/td&gt; &lt;td align="center" bgcolor="#D3D3D3"&gt; &lt;em&gt;a&lt;/em&gt; &lt;/td&gt; &lt;td align="center" bgcolor="#D3D3D3"&gt; &lt;em&gt;b&lt;/em&gt; &lt;/td&gt; &lt;/tr&gt;
&lt;tr height="50px"&gt;  &lt;td&gt;icted &lt;/td&gt;&lt;td bgcolor="#daf2e9"&gt; C2&lt;/td&gt; &lt;td align="center" bgcolor="#D3D3D3"&gt; &lt;em&gt;c&lt;/em&gt; &lt;/td&gt; &lt;td align="center" bgcolor="#D3D3D3"&gt; &lt;em&gt;d&lt;/em&gt; &lt;/td&gt; &lt;/tr&gt;
&lt;/table&gt;
&lt;/center&gt;

- .green[**Accuracy**]: *(a+d)/(a+b+c+d)*
- .green[**Error**]: *(b+c)/(a+b+c+d)*
- .green[**Sensitivity**]: *a/(a+c)*  (true positive, recall)
- .green[**Specificity**]: *d/(b+d)* (true negative)
- .green[**Balanced accuracy**]: *(sensitivity+specificity)/2*

---
# Confusion Table
&lt;br&gt;

```
##           Reference
## Prediction No Yes
##        No  75   5
##        Yes 11  58
##  Accuracy 
## 0.8926174
```







```r
(75 + 58)/(75 + 5 + 11 +58)
## [1] 0.8926174
```


---
# Example - Crabs

Physical measurements on WA crabs, males and females.

.small[*Data source*: Campbell, N. A. &amp; Mahon, R. J. (1974)]

&lt;img src="Workshop1-Week11_files/figure-html/read-crabs-1.png" width="50%" style="display: block; margin: auto;" /&gt;

---
# Example - Crabs

&lt;img src="Workshop1-Week11_files/figure-html/crabs-plot-1.png" width="80%" style="display: block; margin: auto;" /&gt;

---
# Comparing models

.pull-left[

Classification tree

&lt;img src="Workshop1-Week11_files/figure-html/unnamed-chunk-7-1.png" width="100%" style="display: block; margin: auto;" /&gt;
]


.pull-right[

Linear classifier

&lt;img src="Workshop1-Week11_files/figure-html/unnamed-chunk-8-1.png" width="100%" style="display: block; margin: auto;" /&gt;

]

---
# Strengths and Weaknesses

**Strengths:**

- The decision rules provided by trees are very easy to explain, and follow. A simple classification model.
- Trees can handle a mix of predictor types, categorical and quantitative.
- Trees efficiently operate when there are missing values in the predictors.

**Weaknesses:**

- Algorithm is greedy, a better final solution might be obtained by taking a second best split earlier.
- When separation is in linear combinations of variables trees struggle to provide a good classification


---
# Machine learning
&lt;br&gt;
- Materials -- &gt;http://iml.numbat.space
- We use some of the materials there for today's lecture.


---
# Group Project Milestone 4 + peer marking

&lt;br&gt;&lt;br&gt;
**Each team member** please prepare the following documents and all the team members please submit the same files:
.content-box-neutral[
1. **Moodle**: Zip folder with all the Rmd files + any other files required to reproduced the report. All the rmd files must knit. 
2. Deadline 1pm May 24.
]

The following submission will be opened at 10am Tuesday May 25.
.content-box[
1. Presentation uploaded in Moodle after your tutorial by 6:30pm Friday May 28. 
2. Peer review form for milestone 1, 2, 3 and 4 by 6:30pm Friday May 28. 
]




---
# Week 12 Group presentations
&lt;br&gt;&lt;br&gt;
.content-box-neutral[
  Presentations (ETC1010 and ETC5510)]
 - Group order presentations for each tutorial will be available in Moodle by Thursday this week.
 - **Attendance for this session is compulsory.**
 - Each group will have 15min to present their project and all the team members must participate in the presentation.
 - Questions will follow after the presentation.
 

---
# Week 12 Monday in-class asessment
 
.content-box-neutral[ 
Monday (May, 24th: In-class final semester assessment (ETC1010 and ETC5510)
]

- Rstudio Cloud project will be released both in Rstudio Cloud and Moodle. In Rstudio Cloud you will be able to access the project under 

&lt;img src="images/rstudiocloud1.png" width="40%" style="display: block; margin: auto;" /&gt;
- The link to access the space is this one and you should all have access to it:
XXXX
- Copy paste the entire link in the browser. 
- You will need to complete the exercise  and **submit the entire project folder in Moodle by 5:00pm on Monday May 24th**.
- **Late submissions will not be accepted**

---
# Testing during tutorials this week

&lt;br&gt;
- You do do some testing access during the tutorial
- You will also learn about how to download the project from Rstudio Clould
- You will also learn how to upload the project back into Rstudio Cloud
- You will learn about decisions trees



---
# If you experience a technical issue with Rstudio Cloud

&lt;br&gt;

- If you experience an Rstudio Cloud issue please join the Zoom link for your allocated tutorial and the tutors will be able to help you.

- Help about R or knitting problems are **not** technical issues as they are part of the assessment. **No questions related to that will be answered.**

- Please make sure you knit the file as you go and that all the R code chunks are evaluated (eval = TRUE)


---
# It's been wonderful to teach you!


&lt;img src="images/lip-32jBfUrGTRg-unsplash.jpg" width="40%" style="display: block; margin: auto;" /&gt;

Photo by &lt;a href="https://unsplash.com/@liplip?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText"&gt;Lip&lt;/a&gt; on &lt;a href="https://unsplash.com/s/photos/thank-you?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText"&gt;Unsplash&lt;/a&gt;
  
---




background-image: url(images/daniel-olah-pCcGpVsOHoo-unsplash.jpg)
background-size: cover
class: hide-slide-number split-70
count: false

.column.shade_black[.content[

&lt;br&gt;&lt;br&gt;



.bottom_abs.width100[

Lecturer: Patricia Menéndez

Department of Econometrics and Business Statistics&lt;br&gt;





]

&lt;br /&gt;
This work is licensed under a &lt;a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"&gt;Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License&lt;/a&gt;.

&lt;a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"&gt;&lt;img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /&gt;&lt;/a&gt;


]]



&lt;div class="column transition monash-m-new delay-1s" style="clip-path:url(#swipe__clip-path);"&gt;
&lt;div class="background-image" style="background-image:url('images/large.png');background-position: center;background-size:cover;margin-left:3px;"&gt;
&lt;svg class="clip-svg absolute"&gt;
&lt;defs&gt;
&lt;clipPath id="swipe__clip-path" clipPathUnits="objectBoundingBox"&gt;
&lt;polygon points="0.5745 0, 0.5 0.33, 0.42 0, 0 0, 0 1, 0.27 1, 0.27 0.59, 0.37 1, 0.634 1, 0.736 0.59, 0.736 1, 1 1, 1 0, 0.5745 0" /&gt;
&lt;/clipPath&gt;
&lt;/defs&gt;	
&lt;/svg&gt;
&lt;/div&gt;
&lt;/div&gt;
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="libs/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLanguage": "r",
"highlightLines": true,
"highlightSpans": false,
"countIncrementalSlides": false,
"slideNumberFormat": "%current%/%total%",
"navigation": {
"scroll": false,
"touch": true,
"click": false
},
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'assets/mathjax-local/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
